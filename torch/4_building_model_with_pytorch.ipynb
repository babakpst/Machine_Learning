{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models with pytorch\n",
    "\n",
    "Except for Parameter, the classes we discuss in this video are all subclasses of torch.nn.Module. This is the PyTorch base class meant to encapsulate behaviors specific to PyTorch Models and their components.\n",
    "\n",
    "One important behavior of torch.nn.Module is registering parameters. If a particular Module subclass has learning weights, these weights are expressed as instances of torch.nn.Parameter. The Parameter class is a subclass of torch.Tensor, with the special behavior that when they are assigned as attributes of a Module, they are added to the list of that modules parameters. These parameters may be accessed through the parameters() method on the Module class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "the model is:  TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (activation2): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "the second layer is:  Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model parameters: \n",
      " === parameters for the model === \n",
      "parameters for layer: 0\n",
      " param shape: torch.Size([200, 100])\n",
      "parameters are: \n",
      " Parameter containing:\n",
      "tensor([[-0.0055,  0.0250,  0.0438,  ...,  0.0833, -0.0740,  0.0096],\n",
      "        [ 0.0424, -0.0706, -0.0407,  ..., -0.0273, -0.0934, -0.0322],\n",
      "        [-0.0571,  0.0439, -0.0869,  ...,  0.0190, -0.0533,  0.0232],\n",
      "        ...,\n",
      "        [-0.0463,  0.0288,  0.0873,  ..., -0.0767, -0.0849,  0.0370],\n",
      "        [ 0.0470,  0.0939,  0.0225,  ..., -0.0176, -0.0340,  0.0528],\n",
      "        [-0.0579, -0.0891, -0.0328,  ...,  0.0437,  0.0957,  0.0766]],\n",
      "       requires_grad=True)\n",
      "parameters for layer: 1\n",
      " param shape: torch.Size([200])\n",
      "parameters are: \n",
      " Parameter containing:\n",
      "tensor([-0.0636, -0.0490,  0.0027,  0.0867, -0.0262,  0.0223,  0.0805,  0.0448,\n",
      "        -0.0354,  0.0436,  0.0592, -0.0370, -0.0396,  0.0883,  0.0148,  0.0750,\n",
      "         0.0261, -0.0723, -0.0671, -0.0343, -0.0798, -0.0270,  0.0964,  0.0678,\n",
      "         0.0332,  0.0242, -0.0268, -0.0280,  0.0202, -0.0054,  0.0341, -0.0855,\n",
      "         0.0283, -0.0730, -0.0952,  0.0717, -0.0119, -0.0804,  0.0937,  0.0770,\n",
      "        -0.0436,  0.0799,  0.0416, -0.0236, -0.0176, -0.0618, -0.0221,  0.0718,\n",
      "         0.0282, -0.0667,  0.0699,  0.0782, -0.0744,  0.0369, -0.0713,  0.0868,\n",
      "         0.0710, -0.0771,  0.0214,  0.0555,  0.0496,  0.0346,  0.0321,  0.0444,\n",
      "         0.0307,  0.0725, -0.0689,  0.0972,  0.0433,  0.0299,  0.0124, -0.0086,\n",
      "        -0.0224,  0.0387,  0.0879, -0.0712, -0.0945,  0.0659,  0.0651, -0.0741,\n",
      "        -0.0782,  0.0316, -0.0003,  0.0307,  0.0743, -0.0791, -0.0653, -0.0701,\n",
      "        -0.0603, -0.0225, -0.0184,  0.0644,  0.0715, -0.0006,  0.0469,  0.0064,\n",
      "        -0.0843, -0.0534, -0.0463, -0.0121,  0.0375, -0.0556,  0.0376, -0.0384,\n",
      "         0.0617, -0.0953,  0.0480,  0.0184,  0.0556, -0.0793, -0.0915,  0.0421,\n",
      "         0.0200,  0.0977, -0.0871, -0.0410, -0.0659,  0.0554,  0.0990, -0.0059,\n",
      "        -0.0402, -0.0966,  0.0064, -0.0664,  0.0528,  0.0002, -0.0759, -0.0018,\n",
      "         0.0158, -0.0208, -0.0583, -0.0192, -0.0102,  0.0402,  0.0533,  0.0918,\n",
      "        -0.0706,  0.0852, -0.0469,  0.0658, -0.0664,  0.0681, -0.0426,  0.0599,\n",
      "        -0.0116,  0.0227,  0.0939,  0.0588,  0.0549,  0.0565,  0.0530, -0.0065,\n",
      "        -0.0080, -0.0454, -0.0743, -0.0426, -0.0127, -0.0852, -0.0783, -0.0275,\n",
      "        -0.0243, -0.0169,  0.0304, -0.0910, -0.0545, -0.0575,  0.0406, -0.0747,\n",
      "        -0.0548,  0.0697, -0.0435, -0.0768, -0.0259, -0.0689,  0.0135, -0.0886,\n",
      "         0.0627, -0.0009,  0.0568,  0.0515, -0.0043,  0.0535, -0.0907, -0.0980,\n",
      "        -0.0069,  0.0971,  0.0078, -0.0806, -0.0238,  0.0796,  0.0732, -0.0462,\n",
      "        -0.0607,  0.0343, -0.0485, -0.0167,  0.0294, -0.0680,  0.0938, -0.0853],\n",
      "       requires_grad=True)\n",
      "parameters for layer: 2\n",
      " param shape: torch.Size([10, 200])\n",
      "parameters are: \n",
      " Parameter containing:\n",
      "tensor([[-0.0045,  0.0425, -0.0350,  ..., -0.0173, -0.0589,  0.0664],\n",
      "        [ 0.0318,  0.0673, -0.0499,  ...,  0.0163, -0.0228,  0.0345],\n",
      "        [-0.0665, -0.0631, -0.0513,  ...,  0.0382,  0.0214,  0.0349],\n",
      "        ...,\n",
      "        [ 0.0452, -0.0078, -0.0065,  ..., -0.0139,  0.0082, -0.0525],\n",
      "        [-0.0150,  0.0394, -0.0596,  ...,  0.0608, -0.0235,  0.0040],\n",
      "        [ 0.0672, -0.0143, -0.0568,  ...,  0.0581,  0.0051, -0.0508]],\n",
      "       requires_grad=True)\n",
      "parameters for layer: 3\n",
      " param shape: torch.Size([10])\n",
      "parameters are: \n",
      " Parameter containing:\n",
      "tensor([ 0.0689,  0.0465, -0.0259,  0.0361, -0.0054, -0.0622,  0.0338, -0.0031,\n",
      "        -0.0087,  0.0578], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer parameters: \n",
      "Parameter containing:\n",
      "tensor([[-0.0045,  0.0425, -0.0350,  ..., -0.0173, -0.0589,  0.0664],\n",
      "        [ 0.0318,  0.0673, -0.0499,  ...,  0.0163, -0.0228,  0.0345],\n",
      "        [-0.0665, -0.0631, -0.0513,  ...,  0.0382,  0.0214,  0.0349],\n",
      "        ...,\n",
      "        [ 0.0452, -0.0078, -0.0065,  ..., -0.0139,  0.0082, -0.0525],\n",
      "        [-0.0150,  0.0394, -0.0596,  ...,  0.0608, -0.0235,  0.0040],\n",
      "        [ 0.0672, -0.0143, -0.0568,  ...,  0.0581,  0.0051, -0.0508]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0689,  0.0465, -0.0259,  0.0361, -0.0054, -0.0622,  0.0338, -0.0031,\n",
      "        -0.0087,  0.0578], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.activation2 = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        return x\n",
    "  \n",
    "\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print(\"\\n\\nthe model is: \", tinymodel)\n",
    "print(\"\\n\\nthe second layer is: \", tinymodel.linear2)\n",
    "print(\"\\n\\nModel parameters: \")\n",
    "\n",
    "print(\" === parameters for the model === \")\n",
    "i = 0\n",
    "for param in tinymodel.parameters():\n",
    "    print(f\"parameters for layer: {i}\")\n",
    "    print(f\" param shape: {param.shape}\")\n",
    "    \n",
    "    print(f\"parameters are: \\n {param}\")\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(\"\\n\\nLayer parameters: \")\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer types\n",
    "\n",
    "### Linear layers\n",
    "The most basic type of neural network layer is a linear or fully connected layer. This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights. If a model/layer has m inputs and n outputs, the weights will be an m x n matrix. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input shape: torch.Size([1, 3])\n",
      " input: tensor([[-0.7298, -0.4829, -1.9811]])\n",
      "\n",
      " weights and bias parameters:\n",
      " param shape: torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2192,  0.5458, -0.0265],\n",
      "        [ 0.1908, -0.1495, -0.1196]], requires_grad=True)\n",
      " param shape: torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([-0.1025,  0.4180], requires_grad=True)\n",
      "\n",
      " weights:  Parameter containing:\n",
      "tensor([[ 0.2192,  0.5458, -0.0265],\n",
      "        [ 0.1908, -0.1495, -0.1196]], requires_grad=True)\n",
      "\n",
      " bias:  Parameter containing:\n",
      "tensor([-0.1025,  0.4180], requires_grad=True)\n",
      "\n",
      " output: tensor([[-0.4735,  0.5879]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      " a linear layer without bias\n",
      "\n",
      " weights parameters:\n",
      " param shape: torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([[-0.2750,  0.0176,  0.1711],\n",
      "        [ 0.0032, -0.3298, -0.3343]], requires_grad=True)\n",
      "\n",
      " weights:  Parameter containing:\n",
      "tensor([[-0.2750,  0.0176,  0.1711],\n",
      "        [ 0.0032, -0.3298, -0.3343]], requires_grad=True)\n",
      "\n",
      " bias:  None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# a linear layer with bias\n",
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.randn(1,3)\n",
    "\n",
    "print(f\" input shape: {x.shape}\")\n",
    "print(\" input:\", x)\n",
    "\n",
    "print(\"\\n weights and bias parameters:\")\n",
    "\n",
    "for param in lin.parameters():\n",
    "    print(f\" param shape: {param.shape}\")\n",
    "    print(param)\n",
    "\n",
    "\n",
    "print(\"\\n weights: \", lin.weight)\n",
    "print(\"\\n bias: \", lin.bias)\n",
    "\n",
    "\n",
    "y = lin(x)\n",
    "\n",
    "print(\"\\n output:\", y)\n",
    "\n",
    "\n",
    "\n",
    "# a linear layer without bias\n",
    "print(\"\\n\\n a linear layer without bias\")\n",
    "lin_woBias = torch.nn.Linear(3, 2, bias=False)\n",
    "\n",
    "print(f\"\\n weights parameters:\")\n",
    "\n",
    "for param in lin_woBias.parameters():\n",
    "    print(f\" param shape: {param.shape}\")\n",
    "    print(param)\n",
    "\n",
    "print(\"\\n weights: \", lin_woBias.weight)\n",
    "print(\"\\n bias: \", lin_woBias.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where a word’s immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional layer is like a window that scans over the image, looking for a pattern it recognizes. These patterns are called features, and one of the parameters of a convolutional layer is the number of features we would like it to learn. This is the second argument to the constructor is the number of output features. Here, we’re asking our layer to learn 6 features.\n",
    "\n",
    "Just above, I likened the convolutional layer to a window - but how big is the window? The third argument is the window or kernel size. Here, the “5” means we’ve chosen a 5x5 kernel. (If you want a kernel with height different from width, you can specify a tuple for this argument - e.g., (3, 5) to get a 3x5 convolution kernel.)\n",
    "\n",
    "The output of a convolutional layer is an activation map - a spatial representation of the presence of features in the input tensor. conv1 will give us an output tensor of 6x28x28; 6 is the number of features, and 28 is the height and width of our map. (The 28 comes from the fact that when scanning a 5-pixel window over a 32-pixel row, there are only 28 valid positions.)\n",
    "\n",
    "We then pass the output of the convolution through a ReLU activation function (more on activation functions later), then through a max pooling layer. The max pooling layer takes features near each other in the activation map and groups them together. It does this by reducing the tensor, merging every 2x2 group of cells in the output into a single cell, and assigning that cell the maximum value of the 4 cells that went into it. This gives us a lower-resolution version of the activation map, with dimensions 6x14x14.\n",
    "\n",
    "Our next convolutional layer, conv2, expects 6 input channels (corresponding to the 6 features sought by the first layer), has 16 output channels, and a 3x3 kernel. It puts out a 16x12x12 activation map, which is again reduced by a max pooling layer to 16x6x6. Prior to passing this output to the linear layers, it is reshaped to a 16 * 6 * 6 = 576-element vector for consumption by the next layer.\n",
    "\n",
    "There are convolutional layers for addressing 1D, 2D, and 3D tensors. There are also many more optional arguments for a conv layer constructor, including stride length(e.g., only scanning every second or every third position) in the input, padding (so you can scan out to the edges of the input), and more. See the documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent layers\n",
    "\n",
    "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n",
    "\n",
    "The internal structure of an RNN layer - or its variants, the LSTM (long short-term memory) and GRU (gated recurrent unit) - is moderately complex and beyond the scope of this video, but we’ll show you what one looks like in action with an LSTM-based part-of-speech tagger (a type of classifier that tells you if a word is a noun, verb, etc.):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
